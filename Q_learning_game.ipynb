{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GolfGame():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.field = np.arange(20).reshape((4,5))\n",
    "        self.state = 19\n",
    "        \n",
    "        self.player_y_pos = 3\n",
    "        self.player_x_pos = 4\n",
    "        \n",
    "        self.ball_y_loc = 3\n",
    "        self.ball_x_loc = 4\n",
    "        \n",
    "    \n",
    "    def reset_game(self):\n",
    "        self.player_y_pos = 3\n",
    "        self.player_x_pos = 4\n",
    "        \n",
    "        self.ball_y_loc = 3\n",
    "        self.ball_x_loc = 4\n",
    "    \n",
    "\n",
    "    def random_action(self):\n",
    "        actions = ['up','down','right','left']\n",
    "        action = random.choice(actions)\n",
    "        \n",
    "        return action \n",
    "        \n",
    "    \n",
    "    def check_done(self):\n",
    "        \n",
    "        if self.state in [7,8,12,13,15]:\n",
    "            done = True\n",
    "        elif self.state == 0:\n",
    "            done = True \n",
    "        else: \n",
    "            done = False \n",
    "            \n",
    "        return done \n",
    "\n",
    "    \n",
    "    def check_reward(self):\n",
    "        \n",
    "        if self.state == 0: \n",
    "            reward = 100\n",
    "        elif self.state in [7,8,12,13,15]:\n",
    "            reward = -10\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        return reward \n",
    "    \n",
    "    \n",
    "    def move(self, action):\n",
    "        \n",
    "        actions = ['up','down','right','left']\n",
    "        action = actions[action]\n",
    "        \n",
    "        update = 0\n",
    "        if action == \"up\" and self.ball_y_loc > 0:\n",
    "            self.ball_y_loc -=1\n",
    "            \n",
    "        elif action == \"down\" and self.ball_y_loc < 3:\n",
    "            self.ball_y_loc +=1\n",
    "            \n",
    "        elif action == \"right\" and self.ball_x_loc < 4:\n",
    "            self.ball_x_loc += 1\n",
    "            \n",
    "        elif action == \"left\" and self.ball_x_loc > 0:\n",
    "            self.ball_x_loc -= 1\n",
    "        else:\n",
    "            self.ball_x_loc = self.ball_x_loc\n",
    "            \n",
    "    \n",
    "    def update_player_loc(self):\n",
    "        self.player_y_pos = self.ball_y_loc\n",
    "        self.player_x_pos = self.ball_x_loc\n",
    "        \n",
    "        \n",
    "    def update_state(self):\n",
    "        self.state = self.field[self.ball_y_loc][self.ball_x_loc]\n",
    "    \n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "        \n",
    "\n",
    "    def play_game(self, action):\n",
    "\n",
    "        self.move(action)\n",
    "        self.update_state()\n",
    "        self.update_player_loc()\n",
    "        \n",
    "        done = self.check_done()\n",
    "        reward = self.check_reward()        \n",
    "        \n",
    "        return self.state, reward, done         \n",
    "    \n",
    "    \n",
    "    def print_location(self):\n",
    "        print(\"player location: (\",self.player_y_pos,\", \", self.player_x_pos,\")\")\n",
    "        print(\"ball location: (\",self.ball_y_loc,\", \", self.ball_x_loc,\")\")\n",
    "        print(\"state: \",self.state)\n",
    "        \n",
    "        \n",
    "    def visualize_game(self):\n",
    "        print(\"Time: \", time_variable)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####training with a random action \n",
    "\n",
    "num_episodes = 100000\n",
    "alpha = 0.1 \n",
    "gamma = 0.9 \n",
    "\n",
    "epsilon = .9\n",
    "epsilon_decay = .001\n",
    "epsilon_min = .2\n",
    "\n",
    "Q_table = np.zeros((20,4))\n",
    "golfgame = GolfGame()\n",
    "\n",
    "action_map = {\"up\":0, \"down\":1, \"right\":2, \"left\":3}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    golfgame.reset_game()\n",
    "    state = golfgame.get_state()\n",
    "\n",
    "    #selection action based on greedy epsilon policy\n",
    "    if np.random.random() < epsilon:\n",
    "        action_name = golfgame.random_action()\n",
    "        action = action_map[action_name]\n",
    "    else:\n",
    "        action = np.argmax(Q_table[state, :])\n",
    "                    \n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    \n",
    "    while not done: \n",
    "\n",
    "        state_next, reward, done = golfgame.play_game(action)\n",
    "        \n",
    "        #selection action based on greedy epsilon policy\n",
    "        if np.random.random() < epsilon:\n",
    "            action_name_next = golfgame.random_action()\n",
    "            action_next = action_map[action_name_next]\n",
    "        else:\n",
    "            action_next = np.argmax(Q_table[state_next, :])\n",
    "\n",
    "        if epsilon > epsilon_min:    \n",
    "            epsilon -= epsilon_decay\n",
    "            \n",
    "        #print(action, action_next)\n",
    "\n",
    "\n",
    "        Q = Q_table[state, action]\n",
    "        Q_next = np.max(Q_table[state_next, :])\n",
    "\n",
    "        Q_table[state, action] = Q + alpha * (reward + gamma * Q_next - Q)\n",
    "\n",
    "        state, action = state_next, action_next \n",
    "        \n",
    "\n",
    "        #golfgame.print_location()\n",
    "        #print(action)\n",
    "        \n",
    "        #if reward ==100:\n",
    "            #print('won', i)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "14\n",
      "9\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#print path\n",
    "state = 19\n",
    "print(state)\n",
    "while state!=0:\n",
    "    move = Q_table[[state]].argmax()\n",
    "    if move==0:\n",
    "        state -=5\n",
    "    elif move==1:\n",
    "        state+=5\n",
    "    elif move==2:\n",
    "        state+=1\n",
    "    elif move==3:\n",
    "        state-=1\n",
    "\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
